{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nobiquad/ESL/blob/main/Traffic_Sign_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2U0Gmdgy0te"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install torch torchvision matplotlib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import mobilenet_v2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\" Urządzenie: {device}\")\n",
        "\n",
        "GTSRB_CLASSES = [\n",
        "    \"Prędkość 20\", \"Prędkość 30\", \"Prędkość 50\", \"Prędkość 60\", \"Prędkość 70\",\n",
        "    \"Prędkość 80\", \"Koniec 80\", \"Prędkość 100\", \"Prędkość 120\", \"Zakaz wyprzedzania\",\n",
        "    \"Zakaz wyprzedzania dla ciężarówek\", \"Pierwszeństwo na skrzyżowaniu\", \"Droga z pierwszeństwem\",\n",
        "    \"Ustąp pierwszeństwa\", \"Stop\", \"Zakaz wjazdu\", \"Zakaz wjazdu dla ciężarówek\",\n",
        "    \"Inny zakaz\", \"Uwaga (ogólne)\", \"Niebezpieczny zakręt w lewo\", \"Niebezpieczny zakręt w prawo\",\n",
        "    \"Podwójny zakręt\", \"Wyboista droga\", \"Śliska droga\", \"Droga zwęża się z prawej\",\n",
        "    \"Roboty drogowe\", \"Sygnalizacja świetlna\", \"Piesi\", \"Dzieci\", \"Rowerzyści\",\n",
        "    \"Uwaga, lód/śnieg\", \"Dzikie zwierzęta\", \"Koniec ograniczeń\", \"Jedź w prawo\",\n",
        "    \"Jedź w lewo\", \"Tylko prosto\", \"Prosto lub w prawo\", \"Prosto lub w lewo\",\n",
        "    \"Trzymaj się prawej\", \"Trzymaj się lewej\", \"Rondo\", \"Koniec zakazu wyprzedzania\",\n",
        "    \"Koniec zakazu wyprzedzania dla ciężarówek\"\n",
        "]\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "print(\" Pobieranie danych...\")\n",
        "trainset_full = datasets.GTSRB(root='./data', split='train', download=True, transform=train_transform)\n",
        "\n",
        "train_size = int(0.9 * len(trainset_full))\n",
        "val_size = len(trainset_full) - train_size\n",
        "train_ds, val_ds = torch.utils.data.random_split(trainset_full, [train_size, val_size])\n",
        "\n",
        "testset = datasets.GTSRB(root='./data', split='test', download=True, transform=test_transform)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "trainloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "model = mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 43)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_training(model, optimizer, epochs, phase_name):\n",
        "    print(f\"\\n {phase_name} ({epochs} epok)...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(trainloader):.4f} | Train Acc: {100*correct/total:.2f}% | Val Acc: {100*val_correct/val_total:.2f}%\")\n",
        "\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)\n",
        "run_training(model, optimizer, epochs=3, phase_name=\"FAZA 1: Frozen Backbone\")\n",
        "\n",
        "print(\"\\n Odmrażanie wag (Fine-tuning)...\")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "run_training(model, optimizer, epochs=2, phase_name=\"FAZA 2: Unfrozen Fine-tuning\")\n",
        "\n",
        "print(\"\\n Ostateczny Test na zbiorze testowym...\")\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\" Ostateczna dokładność (Test Set): {100 * test_correct / test_total:.2f}%\")\n",
        "\n",
        "def visualize_grid(loader, model, num_images=12):\n",
        "    model.eval()\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    num_images = min(num_images, len(images))\n",
        "\n",
        "    cols = 4\n",
        "    rows = (num_images + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(16, 4 * rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    mean = np.array(IMAGENET_MEAN)\n",
        "    std = np.array(IMAGENET_STD)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_images):\n",
        "            ax = axes[i]\n",
        "            img = images[i]\n",
        "            true_label = labels[i].item()\n",
        "\n",
        "            input_img = img.unsqueeze(0).to(device)\n",
        "            output = model(input_img)\n",
        "            probs = torch.softmax(output, 1)\n",
        "            conf, pred = torch.max(probs, 1)\n",
        "\n",
        "            pred_idx = pred.item()\n",
        "            confidence = conf.item()\n",
        "\n",
        "            img_display = img.cpu().numpy().transpose((1, 2, 0))\n",
        "            img_display = std * img_display + mean\n",
        "            img_display = np.clip(img_display, 0, 1)\n",
        "\n",
        "            ax.imshow(img_display)\n",
        "            ax.axis('off')\n",
        "\n",
        "            is_correct = (pred_idx == true_label)\n",
        "            color = 'green' if is_correct else 'red'\n",
        "            title = f\"{'OK' if is_correct else 'BŁĄD'}: {GTSRB_CLASSES[pred_idx]}\\n({confidence*100:.1f}%)\"\n",
        "            if not is_correct:\n",
        "                title += f\"\\n(Prawda: {GTSRB_CLASSES[true_label]})\"\n",
        "\n",
        "            ax.set_title(title, color=color, fontsize=9, fontweight='bold')\n",
        "\n",
        "    for i in range(num_images, len(axes)): axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_grid(testloader, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bc4e51d"
      },
      "source": [
        "### Załadowanie modelu z pliku `mobilenetv2_gtsrb_multithreaded.pth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSYGDQYIkbfS"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torchao\n",
        "from torchao.quantization import quantize_, Int8WeightOnlyConfig\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"\\n--- KWANTYZACJA ---\")\n",
        "\n",
        "device_cpu = torch.device(\"cpu\")\n",
        "model_fp32 = copy.deepcopy(model).to(device_cpu)\n",
        "model_fp32.eval()\n",
        "\n",
        "model_int8 = copy.deepcopy(model_fp32)\n",
        "\n",
        "quantize_(model_int8,Int8WeightOnlyConfig())\n",
        "\n",
        "print(\" Model został skwantyzowany.\")\n",
        "\n",
        "def get_size_mb(model):\n",
        "    torch.save(model.state_dict(), \"temp_model.pth\")\n",
        "    size = os.path.getsize(\"temp_model.pth\") / 1e6\n",
        "    os.remove(\"temp_model.pth\")\n",
        "    return size\n",
        "\n",
        "def measure_time(model, loader, device, runs=50):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    try:\n",
        "        input_data, _ = next(iter(loader))\n",
        "    except StopIteration:\n",
        "        return 0.0\n",
        "    input_data = input_data.to(device)\n",
        "\n",
        "    for _ in range(5):\n",
        "        with torch.no_grad():\n",
        "            _ = model(input_data)\n",
        "\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(runs):\n",
        "            _ = model(input_data)\n",
        "    end = time.time()\n",
        "\n",
        "    return (end - start) / runs * 1000\n",
        "\n",
        "def eval_acc(model, loader, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    limit = 50\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            if i >= limit: break\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "print(\"\\n --- WYNIKI PORÓWNANIA (CPU) ---\")\n",
        "\n",
        "size_fp32 = get_size_mb(model_fp32)\n",
        "size_int8 = get_size_mb(model_int8)\n",
        "\n",
        "time_fp32 = measure_time(model_fp32, testloader, device_cpu)\n",
        "time_int8 = measure_time(model_int8, testloader, device_cpu)\n",
        "\n",
        "acc_fp32 = eval_acc(model_fp32, testloader, device_cpu)\n",
        "acc_int8 = eval_acc(model_int8, testloader, device_cpu)\n",
        "\n",
        "print(f\"\\n{'METRYKA':<20} | {'FP32 (Oryginał)':<18} | {'INT8 (Kwantyzacja)':<18} | {'ZYSK/STRATA'}\")\n",
        "print(\"-\" * 85)\n",
        "print(f\"{'Rozmiar (MB)':<20} | {size_fp32:.2f} MB           | {size_int8:.2f} MB           | {size_fp32/size_int8:.1f}x mniejszy\")\n",
        "print(f\"{'Czas (ms/batch)':<20} | {time_fp32:.1f} ms           | {time_int8:.1f} ms           | {time_fp32/time_int8:.1f}x szybszy\")\n",
        "print(f\"{'Dokładność (%)':<20} | {acc_fp32:.2f}%            | {acc_int8:.2f}%            | {acc_fp32-acc_int8:.2f} p.p. różnicy\")\n",
        "\n",
        "torch.save(model_int8.state_dict(), \"mobilenet_v2_quantized.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEIC1vOvyu1z7sGMqx8eB3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}